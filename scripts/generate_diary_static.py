#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import re
import html


SITE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
ROOT_DIR = os.path.dirname(SITE_DIR)

MD_LOCAL_PATH = os.path.join(ROOT_DIR, "å¤§å­¦è‡ªè¿°.md")
ABOUT_TEMPLATE = os.path.join(SITE_DIR, "about", "index.html")
DIARY_DIR = os.path.join(SITE_DIR, "diary")
DIARY_INDEX = os.path.join(DIARY_DIR, "index.html")
TAGS_ZATAN_INDEX = os.path.join(SITE_DIR, "tags", "æ‚è°ˆ", "index.html")
ARCHIVES_INDEX = os.path.join(SITE_DIR, "archives", "index.html")


def read_text(path: str) -> str:
    with open(path, "r", encoding="utf-8") as f:
        return f.read()


def write_text(path: str, content: str):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w", encoding="utf-8") as f:
        f.write(content)


def parse_index_targets(index_html: str) -> list:
    targets = re.findall(r"href=\"\.\/entry\.html\?h=([^\"]+)\"", index_html)
    return [html.unescape(t).strip() for t in targets]


def extract_targets_from_md(md: str) -> list:
    """
    ä»æ•´ä»½ Markdown ä¸­æå–æ¡ç›®æ ‡é¢˜ï¼ˆç”¨äºç”Ÿæˆä¸ç›®å½•ï¼‰ã€‚
    è§„åˆ™ï¼š
    - æ”¶é›†æ‰€æœ‰ä»¥ "#### " å¼€å¤´çš„å°æ ‡é¢˜å†…å®¹ï¼›
    - é¢å¤–åŒ…å«æ–‡ä»¶å‰ 5 è¡Œå†…å‡ºç°çš„æ—¥æœŸè¡Œï¼ˆå¦‚ "2025.4.26"ã€"2025å¹´6æœˆ7æ—¥"ï¼‰ã€‚
    ä¿æŒå‡ºç°é¡ºåºï¼Œå»é‡ã€‚
    """
    lines = md.splitlines()
    targets: list[str] = []

    date_patterns = [
        re.compile(r"^\s*\d{4}\.\d{1,2}\.\d{1,2}.*"),
        re.compile(r"^\s*\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥.*"),
    ]

    # æ”¶é›† #### æ ‡é¢˜ä¸ä»»æ„æ—¥æœŸè¡Œï¼ˆæŒ‰å‡ºç°é¡ºåºå»é‡ï¼‰
    for raw in lines:
        line = raw.strip()
        if line.startswith("#### "):
            t = line[5:].strip()
            if t and t not in targets:
                targets.append(t)
            continue
        for pat in date_patterns:
            if pat.match(line):
                t = line
                if t and t not in targets:
                    targets.append(t)
                break
    return targets


def find_section_bounds(md: str, target: str):
    lines = md.splitlines()
    start = -1
    t = target.strip()
    for i, raw in enumerate(lines):
        line = raw.strip()
        if line.startswith("#### "):
            heading = line[5:].strip()
            if heading == t or heading.startswith(t):
                start = i
                break
        else:
            if line == t or line.startswith(t):
                start = i
                break
    if start == -1:
        return 0, len(lines)
    end = len(lines)
    date_line_pat = re.compile(r"^\s*(\d{4}\.\d{1,2}\.\d{1,2}|\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥)\b.*")
    for j in range(start + 1, len(lines)):
        line = lines[j].strip()
        if line.startswith("#### "):
            end = j
            break
        # å¦‚æœå‡ºç°æ–°çš„æ—¥æœŸè¡Œï¼ˆå¦‚ 2025.10.14ï¼‰ï¼Œä¹Ÿè§†ä¸ºä¸‹ä¸€ä¸ªæ¡ç›®å¼€å§‹
        if date_line_pat.match(line):
            end = j
            break
    return start, end


def slugify(title: str) -> str:
    s = title.strip()
    s = re.sub(r"\s+", "-", s)
    s = s.replace(":", "-")
    s = re.sub(r"[^\w\-\.\u4e00-\u9fa5]", "", s)
    s = re.sub(r"-+", "-", s)
    return s


def escape_script_end(s: str) -> str:
    # é˜²æ­¢åˆ‡ç‰‡ä¸­å‡ºç° </script> é€ æˆæ ‡ç­¾æå‰ç»“æŸ
    return s.replace("</script>", "</scr" + "ipt>")


def render_html(base_html: str, page_title: str, md_slice: str) -> str:
    # æ›´æ–° <title>
    base_html = re.sub(
        r"<title>.*?</title>",
        f"<title>å¤§å­¦è‡ªè¿° Â· {html.escape(page_title)} | hecodeğŸ“ğŸ¥</title>",
        base_html,
        count=1,
        flags=re.S,
    )

    # æ›´æ–°é¡µçœ‰æ ‡é¢˜
    base_html = re.sub(
        r"(<div id=\"page-site-info\">\s*<h1 id=\"site-title\">)(.*?)(</h1>)",
        rf"\1å¤§å­¦è‡ªè¿° Â· {html.escape(page_title)}\3",
        base_html,
        count=1,
        flags=re.S,
    )

    # æ ‡è®°ä¸ºæ–‡ç« é¡µï¼Œå¹¶æ³¨å…¥â€œæ‚è°ˆâ€æ ‡ç­¾ï¼ˆä¸åšå®¢æ–‡ç« ä¸€è‡´ï¼‰
    # 1) og:type æ”¹ä¸º article
    base_html = re.sub(
        r"<meta property=\"og:type\" content=\"[^\"]+\">",
        "<meta property=\"og:type\" content=\"article\">",
        base_html,
        count=1,
    )
    # 2) å°† isPost: false æ”¹ä¸º trueï¼Œä»¥å¯ç”¨æ–‡ç« ç›¸å…³çš„æ ·å¼/åŠŸèƒ½
    base_html = re.sub(r"(isPost:\s*)(false)", r"\1true", base_html)
    # 3) åœ¨ </head> å‰æ³¨å…¥æ–‡ç« æ ‡ç­¾ meta
    base_html = re.sub(
        r"</head>",
        "<meta property=\"article:tag\" content=\"æ‚è°ˆ\"></head>",
        base_html,
        count=1,
        flags=re.S,
    )

    # å°†æ–‡ç« å®¹å™¨æ›¿æ¢ä¸º markdown ç‰‡æ®µ + marked æ¸²æŸ“
    ac_pattern = r"(<div id=\"article-container\">)(.*?)(</div></div>)"
    md_block = escape_script_end(md_slice)
    # ä½¿ç”¨ç‹¬ç«‹çš„ md å®¹å™¨ï¼Œé¿å…è¦†ç›–æ ‡ç­¾åŒºå—
    tag_block = (
        "<div class=\"tag_share\">"
        "<div class=\"post-meta__tag-list\">"
        "<a class=\"post-meta__tags\" href=\"/tags/%E6%9D%82%E8%B0%88/\">æ‚è°ˆ</a>"
        "</div>"
        "</div>"
    )
    replacement = (
        "<div id=\"md-container\"></div>"
        "<script id=\"md\" type=\"text/markdown\">" + md_block + "</script>"
        "<script src=\"https://cdn.jsdelivr.net/npm/marked/marked.min.js\"></script>"
        "<script>document.getElementById('md-container').innerHTML = marked.parse(document.getElementById('md').textContent);</script>"
        + tag_block
    )
    base_html = re.sub(ac_pattern, rf"\1{replacement}\3", base_html, count=1, flags=re.S)
    return base_html


def parse_date_from_title(title: str):
    """ä»æ ‡é¢˜è§£ææ—¥æœŸç»„ä»¶ (year, month, day)ã€‚æ”¯æŒä¸¤ç§æ ¼å¼ï¼š
    - 2025.10.14
    - 2025å¹´10æœˆ14æ—¥
    è‹¥æ— æ³•è§£æï¼Œè¿”å› Noneã€‚
    """
    t = title.strip()
    m = re.match(r"^(\d{4})\.(\d{1,2})\.(\d{1,2})\b", t)
    if m:
        y, mm, dd = m.groups()
        return int(y), int(mm), int(dd)
    m2 = re.match(r"^(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥\b", t)
    if m2:
        y, mm, dd = m2.groups()
        return int(y), int(mm), int(dd)
    return None


def build_article_sort_item(year: int, month: int, day: int, url_path: str, title_text: str) -> str:
    iso = f"{year:04d}-{month:02d}-{day:02d}T00:00:00.000Z"
    display = f"{year:04d}-{month:02d}-{day:02d}"
    safe_title = html.escape(title_text)
    # ä½¿ç”¨ç«™ç‚¹å·²æœ‰çš„å…œåº• 404 å ä½å›¾ï¼Œé¿å…å¤–é“¾å¤±è´¥
    img_src = "/img/404.jpg"
    return (
        f"<div class=\"article-sort-item\">"
        f"<a class=\"article-sort-item-img\" href=\"{url_path}\" title=\"{safe_title}\">"
        f"<img src=\"{img_src}\" alt=\"{safe_title}\" onerror=\"this.onerror=null;this.src='/img/404.jpg'\"></a>"
        f"<div class=\"article-sort-item-info\">"
        f"<div class=\"article-sort-item-time\"><i class=\"far fa-calendar-alt\"></i>"
        f"<time class=\"post-meta-date-created\" datetime=\"{iso}\" title=\"å‘è¡¨äº {display}\">{display}</time></div>"
        f"<a class=\"article-sort-item-title\" href=\"{url_path}\" title=\"{safe_title}\">{safe_title}</a>"
        f"</div>"
        f"</div>"
    )


def insert_items_into_tag_page(tag_html: str, items_html: list[str], year: int) -> str:
    # ç¡®ä¿å­˜åœ¨å¹´ä»½æ ‡è¯†ï¼ˆä½¿ç”¨æ­£å¸¸å¼•å·åŒ¹é…/æ’å…¥ï¼‰
    if f'<div class="article-sort-item year">{year}</div>' not in tag_html and f'<div class="article-sort-item year">{year}</div>' not in tag_html:
        tag_html = re.sub(
            r'(<div class="article-sort">)',
            rf'\1<div class="article-sort-item year">{year}</div>',
            tag_html,
            count=1,
        )
    # å°†æ–°æ¡ç›®è¿½åŠ åˆ° article-sort å®¹å™¨ä¸åˆ†é¡µä¹‹é—´
    tag_html = re.sub(
        r'(</div><nav id="pagination">)',
        "".join(items_html) + r"\1",
        tag_html,
        count=1,
    )
    return tag_html


def insert_items_into_archives(arc_html: str, items_html: list[str], year: int) -> str:
    # ç¡®ä¿å­˜åœ¨å¹´ä»½æ ‡è¯†ä¸ç»Ÿè®¡æ–‡æ¡ˆä¸å˜æ›´ï¼ˆæ­£å¸¸å¼•å·ï¼‰
    if f'<div class="article-sort-item year">{year}</div>' not in arc_html and f'<div class="article-sort-item year">{year}</div>' not in arc_html:
        arc_html = re.sub(
            r'(<div class="article-sort">)',
            rf'\1<div class="article-sort-item year">{year}</div>',
            arc_html,
            count=1,
        )
    arc_html = re.sub(
        r'(</div><nav id="pagination">)',
        "".join(items_html) + r"\1",
        arc_html,
        count=1,
    )
    return arc_html


def main():
    print("[generate] start")
    index_html = read_text(DIARY_INDEX)
    md = read_text(MD_LOCAL_PATH)
    # ç›®æ ‡é›†åˆï¼šä»¥ Markdown ä¸ºå‡†ï¼Œä¿è¯å…¨éƒ¨æ¡ç›®è¢«ç”Ÿæˆ
    targets = extract_targets_from_md(md)
    if not targets:
        raise RuntimeError("æœªåœ¨ã€Šå¤§å­¦è‡ªè¿°.mdã€‹å†…æ‰¾åˆ°ä»»ä½•æ¡ç›®æ ‡é¢˜ï¼ˆ#### æˆ–æ—¥æœŸè¡Œï¼‰")
    print(f"[generate] targets(from md): {len(targets)}")
    base_tpl = read_text(ABOUT_TEMPLATE)
    for t in targets:
        start, end = find_section_bounds(md, t)
        lines = md.splitlines()
        slice_text = "\n".join(lines[start:end]).strip()
        html_out = render_html(base_tpl, t, slice_text)
        out_path = os.path.join(DIARY_DIR, f"{slugify(t)}.html")
        write_text(out_path, html_out)
        print(f"[generate] wrote {out_path}")

        # è¿ç§»ä¸º Hexo é£æ ¼ Postï¼š/YYYY/MM/DD/<slug>/index.html
        date = parse_date_from_title(t)
        if date:
            y, m, d = date
            post_slug = slugify(f"å¤§å­¦è‡ªè¿°-{t}")
            post_dir = os.path.join(SITE_DIR, f"{y}", f"{m:02d}", f"{d:02d}", post_slug)
            post_index = os.path.join(post_dir, "index.html")
            write_text(post_index, html_out)
            print(f"[migrate] post {post_index}")
        else:
            print(f"[migrate] skip hexo post for non-date title: {t}")

    # æ›´æ–°ç´¢å¼•ï¼šæ ¹æ®å…¨éƒ¨ targets é‡å†™ <ul class="toc"> åˆ—è¡¨
    def build_list(ts: list[str]) -> str:
        items = []
        for t in ts:
            items.append(f'<li><a href="./{slugify(t)}.html">{html.escape(t)}</a></li>')
        return "\n".join(items)

    toc_list = build_list(targets)
    new_index = re.sub(
        r"(<ul class=\"toc\">)(.*?)(</ul>)",
        rf"\1\n{toc_list}\n\3",
        index_html,
        flags=re.S,
    )
    write_text(DIARY_INDEX, new_index)
    print("[generate] index updated")

    # æ›´æ–° tags/æ‚è°ˆ ä¸ archives é¡µé¢ï¼Œæ’å…¥å·²è¿ç§»çš„ Post é“¾æ¥ï¼ˆä»…é™è§£æåˆ°æ—¥æœŸçš„æ¡ç›®ï¼‰
    try:
        tag_html = read_text(TAGS_ZATAN_INDEX)
        arc_html = read_text(ARCHIVES_INDEX)
        items_for_tag: list[str] = []
        items_for_arc: list[str] = []
        for t in targets:
            date = parse_date_from_title(t)
            if not date:
                continue
            y, m, d = date
            post_slug = slugify(f"å¤§å­¦è‡ªè¿°-{t}")
            url_path = f"/{y}/{m:02d}/{d:02d}/{post_slug}/"
            title_text = f"å¤§å­¦è‡ªè¿° Â· {t}"
            item = build_article_sort_item(y, m, d, url_path, title_text)
            items_for_tag.append(item)
            items_for_arc.append(item)
        if items_for_tag:
            new_tag_html = insert_items_into_tag_page(tag_html, items_for_tag, items_for_tag and date[0] or 2025)
            write_text(TAGS_ZATAN_INDEX, new_tag_html)
            print("[migrate] tags/æ‚è°ˆ updated")
        if items_for_arc:
            new_arc_html = insert_items_into_archives(arc_html, items_for_arc, items_for_arc and date[0] or 2025)
            write_text(ARCHIVES_INDEX, new_arc_html)
            print("[migrate] archives updated")
    except Exception as e:
        print(f"[migrate] update tag/archive failed: {e}")
    print("[generate] done")


if __name__ == "__main__":
    main()